install.packages("rvest")
#Loading the rvest package
library('rvest')
#Specifying the url for desired website to be scraped
url <- 'https://www.alpsonline.org/reservation/calendar?hut_id=65'
#Reading the HTML code from the website
webpage <- read_html(url)
webpage
html_nodes(webpage,'.text-primary')
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'info')
rank_data_html
#Using CSS selectors to scrap the rankings section
# rank_data_html <-
html_nodes(webpage,'span')
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
html_text(rank_data_html)
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
rank_data[rank_data %like% Koordinate]
library('data.table')
rank_data[grep("Koordinaten", rank_data)]
koo <- gsub("Koordinaten:\n", "", koo)
koo <- rank_data[grep("Koordinaten", rank_data)]
koo <- gsub("Koordinaten:\n", "", koo)
koo
gsub(".*(\\d*)\\.(\\d*).(\\d*)\\.(\\d*)", "\\1.\\2 - \\3.\\4", koo)
gsub(".*(\\d*).(\\d*).(\\d*).(\\d*)", "\\1.\\2 - \\3.\\4", koo)
gsub(".*(\\d*).(\\d*).(\\d*).(\\d*)", "\\1", koo)
gsub(" *(\\d*).(\\d*).(\\d*).(\\d*)", "\\1", koo)
gsub(" *(\\d*).*(\\d*)", "\\1", koo)
gsub(" *(\\d*).*(\\d*)", "\\1\\2", koo)
gsub(" *(\\d*).(\\d*)", "\\1\\2", koo)
gsub(" *(\\d*).(\\d*).*(\\d*).(\\d*)", "\\1\\2", koo)
library(rgdal)
install.packages("rgdal")
coord <- data.table(x = gsub(" *(\\d*).(\\d*).*(\\d*).(\\d*)", "\\1\\2", koo),
)
library(rgdal)
gsub(" *(\\d*).(\\d*).*(\\d*).(\\d*)", "\\1\\2", koo)
gsub(" *(\\d*).(\\d*).*(\\d*).(\\d*)", "\\3\\4", koo)
koo
gsub(" *(\\d*).(\\d*).*(\\d*).(\\d*)", "\\1\\2", koo)
gsub(" *(\\d*).(\\d*).(\\d*).(\\d*)", "\\3\\4", koo)
gsub(" *(\\d*).(\\d*).*(\\d*)", "\\3\\4", koo)
gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo)
gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo)
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coordinates(coord)
coordinates(coord)  <- c("x", "y")
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", as.numeric("\\1\\2"), koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", as.numeric("\\3\\4"), koo))
coordinates(coord) <- c("x", "y")
coord
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", as.numeric("\\1\\2"), koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", as.numeric("\\3\\4"), koo))
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", as.numeric("\\1\\2"), koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", as.numeric("\\3\\4"), koo))
coord
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coord
str(coord)
coord[, x:= as.numeric(x)]
coord[, y:= as.numeric(y)]
coordinates(coord) <- c("x", "y")
proj4string(coord) <- CRS("+init=epsg:32632")
coord
proj4string(coord) <- CRS("+init=epsg:4326")
url <- 'https://www.alpsonline.org/reservation/calendar?hut_id=79'
#Reading the HTML code from the website
webpage <- read_html(url)
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
koo <- rank_data[grep("Koordinaten", rank_data)]
koo <- gsub("Koordinaten:\n", "", koo)
gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo)
gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coord[, x:= as.numeric(x)]
coord[, y:= as.numeric(y)]
coordinates(coord) <- c("x", "y")
proj4string(coord) <- CRS("+init=epsg:32632")
proj4string(coord)
spTransform(xcoord, CRS("+init=epsg:4326")
)
spTransform(coord, CRS("+init=epsg:4326"))
proj4string(coord) <- CRS("+init=epsg:32732")
proj4string(coord)
spTransform(coord, CRS("+init=epsg:4326"))
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coord[, x:= as.numeric(x)]
coord[, y:= as.numeric(y)]
coordinates(coord) <- c("x", "y")
proj4string(coord) <- CRS("+proj=utm +zone=32 +south=T ellps=WGS84")
proj4string(coord)
spTransform(coord, CRS("+init=epsg:4326"))
proj4string(coord) <- CRS("+proj=utm +zone=32 ellps=WGS84")
proj4string(coord)
coord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coord[, x:= as.numeric(x)]
coordinates(coord) <- c("x", "y")
proj4string(coord) <- CRS("+proj=utm +zone=32 ellps=WGS84")
spTransform(coord, CRS("+init=epsg:4326"))
proj4string(coord)
coord[, y:= as.numeric(y)]
proj4string(coord) <- CRS("+proj=utm +zone=32 +N ellps=WGS84")
oord <- data.table(x = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\1\\2", koo),
y = gsub(" *(\\d*).(\\d*)\\D*(\\d*).(\\d*)", "\\3\\4", koo))
coord[, x:= as.numeric(x)]
coord[, y:= as.numeric(y)]
coordinates(coord) <- c("x", "y")
proj4string(coord) <- CRS("+proj=utm +zone=32 +N ellps=WGS84")
proj4string(coord)
spTransform(coord, CRS("+init=epsg:4326"))
find_UTM_zone <- function(longitude, latitude) {
# Special zones for Svalbard and Norway
if (latitude >= 72.0 && latitude < 84.0 )
if (longitude >= 0.0  && longitude <  9.0)
return(31);
if (longitude >= 9.0  && longitude < 21.0)
return(33)
if (longitude >= 21.0 && longitude < 33.0)
return(35)
if (longitude >= 33.0 && longitude < 42.0)
return(37)
(floor((longitude + 180) / 6) %% 60) + 1
}
find_UTM_zone(10.066094, 46.881009)
find_UTM_hemisphere(46.881009)
find_UTM_hemisphere <- function(latitude) {
ifelse(latitude > 0, "north", "south")
}
find_UTM_hemisphere(46.881009)
# returns a DF containing the UTM values, the zone and the hemisphere
longlat_to_UTM <- function(long, lat, units = 'm') {
df <- data.frame(
id = seq_along(long),
x = long,
y = lat
)
sp::coordinates(df) <- c("x", "y")
hemisphere <- find_UTM_hemisphere(lat)
zone <- find_UTM_zone(long, lat)
sp::proj4string(df) <- sp::CRS("+init=epsg:4326")
CRSstring <- paste0(
"+proj=utm +zone=", zone,
" +ellps=WGS84",
" +", hemisphere,
" +units=", units)
if (dplyr::n_distinct(CRSstring) > 1L)
stop("multiple zone/hemisphere detected")
res <- sp::spTransform(df, sp::CRS(CRSstring[1L])) %>%
tibble::as_data_frame() %>%
dplyr::mutate(
zone = zone,
hemisphere = hemisphere
)
res
}
UTM_to_longlat <- function(utm_df, zone, hemisphere) {
CRSstring <- paste0("+proj=utm +zone=", zone, " +", hemisphere)
utmcoor <- sp::SpatialPoints(utm_df, proj4string = sp::CRS(CRSstring))
longlatcoor <- sp::spTransform(utmcoor, sp::CRS("+init=epsg:4326"))
tibble::as_data_frame(longlatcoor)
}
longlat_to_UTM(10.066094, 46.881009)
library(dplyr)
install.packages("dplyr")
library(dplyr)
find_UTM_zone(10.066094, 46.881009)
find_UTM_hemisphere(46.881009)
longlat_to_UTM(10.066094, 46.881009)
UTM_to_longlat(c(581229, 5192492), find_UTM_zone(10.066094, 46.881009), find_UTM_hemisphere(46.881009))
install.packages("dplyr")
library(dplyr)
url <- 'https://www.alpsonline.org/reservation/calendar?hut_id='
listhu <- data.table()
for(i in 1:200) {
#Reading the HTML code from the website
webpage <- read_html(paste0(url, i))
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
koo <- rank_data[grep("Koordinaten", rank_data)]
temp <- data.table(coord = rank_data[grep("Koordinaten", rank_data)],
Name = rank_data[2])
listhu <- rbind(listhu, temp)
}
i
koo
html_text(rank_data_html)
listhu <- data.table()
for(i in 1:200) {
#Reading the HTML code from the website
webpage <- read_html(paste0(url, i))
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
temp <- data.table(Name = rank_data[2],
coord = rank_data[6])
listhu <- rbind(listhu, temp)
}
listhu
listhu <- data.table()
for(i in 1:300) {
#Reading the HTML code from the website
webpage <- read_html(paste0(url, i))
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
temp <- data.table(Name = rank_data[2],
coord = rank_data[6])
listhu <- rbind(listhu, temp)
cat(i, "\n")
}
listhu
listhu[, coord := gsub("Koordinaten:\n", "", coord)]
listhu[, coord := gsub("Coordinates:\n", "", coord)]
listhu
listhu <- listhu[Name != "Hut warden(s):"]
listhu
listhu[300]
listhu[300, Name]
listhu <- listhu[Name != "Hut warden(s): "]
listhu
listhu <- listhu[Name != "Hut warden(s): "][coord != "XXX.XXX / YYY.YYY"]
listhu[273, coord]
listhu[, coord := gsub(" *", "", coord)]
listhu
listhu <- listhu[Name != "Hut warden(s): "][coord != "XXX.XXX / YYY.YYY"]
listhu[273, coord]
listhu <- listhu[Name != "Hut warden(s): "][coord != "XXX.XXX/YYY.YYY"]
listhu
i=1
#Reading the HTML code from the website
webpage <- read_html(paste0(url, i))
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
rank_data
html_nodes(webpage,'h4')
html_text(html_nodes(webpage,'h4'))
listhu <- data.table()
for(i in 1:300) {
#Reading the HTML code from the website
webpage <- read_html(paste0(url, i))
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
temp <- data.table(Name = html_text(html_nodes(webpage,'h4')),
coord = rank_data[6])
listhu <- rbind(listhu, temp)
cat(i, "\n")
}
install.packages(ggmap)
install.packages("ggmap")
library(ggmap)
listhubu <- copy(listhu)
listhu
listhu[300, coord]
listhu[, coord := gsub("Koordinaten:\n", "", coord)]
listhu[, coord := gsub("Coordinates:\n", "", coord)]
listhu[, coord := gsub(" *", "", coord)]
listhu[300, coord]
listhu <- listhu[coord != "XXX.XXX/YYY.YYY"][coord != ""]
listhu
listhu2<- mutate_geocode(listhu, Name)
?register_google
geocode(c("White House", "Uluru"))
key<-"AIzaSyATd20RDXXK-23rQ91CZzGZTlXzTgRzdmM"
register_google(key = key)
geocode(c("White House", "Uluru"))
mutate_geocode(listhu[1], Name)
listhu2<- mutate_geocode(listhu, Name)
p <- ggmap(get_map("Konstanz", zoom=12))
p + geom_point(data=listhu2, aes(x=lon, y=lat))
p <- ggmap(get_map("Konstanz", zoom=5))
p + geom_point(data=listhu2, aes(x=lon, y=lat))
p <- ggmap(get_map("Konstanz", zoom=7))
p + geom_point(data=listhu2, aes(x=lon, y=lat))
getwd()
wd <- "D:/DG-Papers/GitHub/Website/dorian.gravier.github.io/files/R"
setwd(wd)
write.csv(listhu2, "DAV_hutte_coord.csv", row.names = F)
listhu2[, js := paste0("['", Name, "',", lon, ",", lat, "]")]
listhu2
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, "],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, "]")]
listhu2
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
jsvar.start <- c("var DAVhutten = [")
jsvar.end <- c("];")
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
jsvar
wd
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, js, leaf2)
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2BU <- copy(listhu2)
lishu2[, Name := gsub("'", "", Name)]
listhu2[, Name := gsub("'", "", Name)]
listhu2[, Name := gsub("ü", "", Name)]
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, "],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, "]")]
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2 <- copy(listhu2BU)
listhu2[, Name := gsub("'", "", Name)]
listhu2[, Name := gsub("ü", "ue", Name)]
listhu2[, Name := gsub("ä", "ae", Name)]
listhu2[, Name := gsub("ö", "oe", Name)]
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, "],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, "]")]
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2[Name %like% "Annaberger"]
listhu2 <- copy(listhu2BU)
listhu2[, Name := gsub("'", "", Name)]
listhu2[, Name := gsub("ü", "ue", Name)]
listhu2[, Name := gsub("Ü", "Ue", Name)]
listhu2[, Name := gsub("ä", "ae", Name)]
listhu2[, Name := gsub("Ä", "Ae", Name)]
listhu2[, Name := gsub("ö", "oe", Name)]
listhu2[, Name := gsub("Ö", "Oe", Name)]
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, "],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, "]")]
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
url <- 'https://www.alpsonline.org/reservation/calendar?hut_id='
listhu <- data.table()
for(i in 1:300) {
#Reading the HTML code from the website
webpage <- read_html(paste0(url, i))
#Using CSS selectors to scrap the rankings section
rank_data_html <- html_nodes(webpage,'span')
#Converting the ranking data to text
rank_data <- html_text(rank_data_html)
temp <- data.table(ID = i,
Name = html_text(html_nodes(webpage,'h4')),
coord = rank_data[6])
listhu <- rbind(listhu, temp)
cat(i, "\n")
}
listhubu <- copy(listhu)
listhu[, link := paste0(url, ID)]
listhu[, coord := gsub("Koordinaten:\n", "", coord)]
listhu[, coord := gsub("Coordinates:\n", "", coord)]
listhu[, coord := gsub(" *", "", coord)]
listhu <- listhu[coord != "XXX.XXX/YYY.YYY"][coord != ""]
listhu
data.table(left_join(listhu, listhu2))
listhu[, link := paste0(url, ID)]
listhu[, coord := gsub("Koordinaten:\n", "", coord)]
listhu[, coord := gsub("Coordinates:\n", "", coord)]
listhu[, coord := gsub(" *", "", coord)]
listhu <- listhu[coord != "XXX.XXX/YYY.YYY"][coord != ""]
data.table(left_join(listhu, listhu2))
listhu3 <- data.table(left_join(listhu, listhu2))
listhu3
listhu[, Name := gsub("'", "", Name)]
listhu[, Name := gsub("Ü", "Ue", Name)]
listhu[, Name := gsub("ä", "ae", Name)]
listhu[, Name := gsub("Ä", "Ae", Name)]
listhu[, Name := gsub("ö", "oe", Name)]
listhu[, Name := gsub("Ö", "Oe", Name)]
listhu[, Name := gsub("ü", "ue", Name)]
listhu3 <- data.table(left_join(listhu, listhu2))
listhu3
listhu2 <- data.table(left_join(listhu, listhu2))
write.csv(listhu2, "DAV_hutte_coord.csv", row.names = F)
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, ",'", Link, "'],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, ",'", Link, "'],")]
listhu2
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "'],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "'],")]
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2[Name %like% "Capanna"]
listhu[, Name := gsub("ò", "o", Name)]
listhu2[, Name := gsub("ò", "o", Name)]
listhu2[Name %like% "Wildhornhuette"]
listhu[, Name := gsub("é", "e", Name)]
listhu2[, Name := gsub("é", "e", Name)]
listhu2[Name %like% "Edelwei"]
listhu[, Name := gsub("ß", "ss", Name)]
listhu2[, Name := gsub("ß", "ss", Name)]
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "'],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "'],")]
listhu2
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "']")]
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2
listhu2$js
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
listhu2
#listhu2 <- data.table(left_join(listhu, listhu2))
listhu2[!is.na(lon)]
#listhu2 <- data.table(left_join(listhu, listhu2))
lishu2<- listhu2[!is.na(lon)]
#listhu2 <- data.table(left_join(listhu, listhu2))
listhu2 <- listhu2[!is.na(lon)]
listhu2[1:(nrow(listhu2) - 1), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "'],")]
listhu2[nrow(listhu2), js := paste0("['", Name, "',", lon, ",", lat, ",'", link, "']")]
jsvar <- c(jsvar.start, listhu2$js, jsvar.end)
leaf <- readLines(paste0(dirname(dirname(wd)), "/leaflet.md"))
leaf1 <- leaf[1:grep("// VARIABLE DAVHUTTEN START", leaf)]
leaf2 <- leaf[grep("// VARIABLE DAVHUTTEN END", leaf):length(leaf)]
leafnew <- c(leaf1, jsvar, leaf2)
writeLines(leafnew, paste0(dirname(dirname(wd)), "/leaflet.md"))
